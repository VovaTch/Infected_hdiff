model:
  name: vqvae_lvl_4
  sample_rate: 44100
  slice_time: 0.7430386 # Length of slice to get 2^15 samples
  hidden_size: 64
  latent_width: 128
  latent_depth: 8
  vocabulary_size: 8192
  bottleneck_kernel_size: 0
  channel_dim_change_list: [2, 2, 2]
  amp: False
  input_channels: 8
  dilation_factor: 3
  num_res_block_conv: 5
  activation_type: 'gelu'
  collection_parameter: 8

  encoder_kernel_size: 3
  encoder_dim_change_kernel_size: 3
  decoder_kernel_size: 3
  decoder_dim_change_kernel_add: 0


learning:
  batch_size: 4
  learning_rate: 0.0002
  weight_decay: 0.0
  epochs: 30000
  gradient_clip: 0.5
  beta_ema: 0.9999
  monitored_loss: Validation total loss
  dataset_path: data/music_samples/
  scheduler_type: 'none'
  dataset_name: 'lvl4_dataset'
  eval_split_factor: 0.0
  preload_data_file_path: 'data/music_samples/003-datatensor.pt'
  preload_metadata_file_path: 'data/music_samples/003-metadata.pkl'
  slice_length: 4096


loss:

  reconstruction_loss:
    weight: 1.0
    base_loss_type: 'huber_loss'
    phase_parameter: 1

  alignment_loss:
    weight: 2.5
    base_loss_type: 'l2_loss'

  commitment_loss:
    weight: 2.5
    base_loss_type: 'l2_loss'