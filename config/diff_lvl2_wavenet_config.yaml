model:
  name: lvl2_wavenet_diff
  sample_rate: 44100
  slice_length: 0.7430386 # Length of slice to get 2^15 samples
  # slice_length: 5.0 # Length of slice to get 2^15 samples
  num_encoder_layers: 8
  num_decoder_layers: 8
  filter_size_encoder: 15
  filter_size_decoder: 5
  num_input_channels: 8
  num_filters: 64
  num_steps: 300
  scheduler: linear
  amp: False


learning:
  batch_size: 12
  learning_rate: 0.0001
  weight_decay: 0.001
  epochs: 20000
  gradient_clip: 0.5
  beta_ema: 0.9999
  monitored_loss: Validation total loss
  dataset_path: data/music_samples/
  scheduler_type: 'none'
  dataset_name: 'music_slice_dataset'
  eval_split_factor: 0.01
  preload_data_file_path: 'data/music_samples/002-datatensor_gen.pt'
  preload_metadata_file_path: 'data/music_samples/002-metadata_gen.pkl'
  slice_length: 512
  

loss:

  noise_loss:
    weight: 1.0
    base_loss_type: 'l2_loss'
    phase_parameter: 1