model:
  name: vqvae_lvl_1
  sample_rate: 44100
  slice_length: 0.7430386 # Length of slice to get 2^15 samples
  # slice_length: 5.0 # Length of slice to get 2^15 samples
  hidden_size: 96
  latent_width: 128
  latent_depth: 8
  vocabulary_size: 32768
  bottleneck_kernel_size: 0
  channel_dim_change_list: [2, 2, 2]
  sin_locations: [1, 2, 3]
  amp: False
  input_channels: 8

learning:
  batch_size: 4
  learning_rate: 0.0002
  weight_decay: 0.0
  epochs: 200
  gradient_clip: 0.5
  beta_ema: 0.9999
  monitored_loss: Validation total loss
  dataset_path: data/music_samples/
  scheduler_type: 'none'
  dataset_name: 'music_slice_dataset'
  eval_split_factor: 0.01

  loss_dict:
    loss_beta: 0.5
    loss_reconstruction: 0.1
    loss_mel: 1.0
    loss_mel_sub_1: 1.0
    loss_mel_sub_2: 1.0

mel_spec_config:
  n_fft: 2048
  hop_length: 512
  n_mels: 128
  pad_mode: reflect
  power: 1.0
  norm: "slaney"
  mel_scale: "htk"

mel_spec_sub_1_config:
  n_fft: 1024
  hop_length: 256
  n_mels: 128
  pad_mode: reflect
  power: 2.0
  norm: "slaney"
  mel_scale: "htk"

mel_spec_sub_2_config:
  n_fft: 512
  hop_length: 512
  n_mels: 64
  pad_mode: reflect
  power: 2.0
  norm: "slaney"
  mel_scale: "htk"
  