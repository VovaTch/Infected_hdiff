model:
  name: lvl3_diff
  sample_rate: 44100
  slice_time: 0.7430386 # Length of slice to get 2^15 samples
  in_dim: 8
  hidden_size: 512
  token_collect_size: 64
  num_blocks: 6
  num_heads: 8
  dropout: 0.0
  num_steps: 10
  scheduler: cosine
  amp: False


learning:
  batch_size: 6
  learning_rate: 0.0001
  weight_decay: 0.0001
  epochs: 1000
  gradient_clip: 0.5
  beta_ema: 0.9999
  monitored_loss: Validation total loss
  dataset_path: data/music_samples/
  scheduler_type: 'none'
  dataset_name: 'music_slice_dataset'
  eval_split_factor: 0.01


loss:

  noise_loss:
    weight: 1.0
    base_loss_type: 'l2_loss'
    phase_parameter: 10

  melspec_loss_1:
    weight: 0.1
    base_loss_type: 'huber_loss'
    lin_start: 0.5
    lin_end: 10
    
    melspec_params:
      n_fft: 2048
      hop_length: 512
      n_mels: 128
      pad_mode: reflect
      power: 1.0
      norm: "slaney"
      mel_scale: "htk"

  melspec_loss_2:
    weight: 0.1
    base_loss_type: 'huber_loss'
    lin_start: 1.0
    lin_end: 1.0

    melspec_params:
      n_fft: 1024
      hop_length: 256
      n_mels: 128
      pad_mode: reflect
      power: 2.0
      norm: "slaney"
      mel_scale: "htk"

  melspec_loss_3:
    weight: 0.1
    base_loss_type: 'huber_loss'
    lin_start: 0.1
    lin_end: 20

    melspec_params:
      n_fft: 512
      hop_length: 512
      n_mels: 64
      pad_mode: reflect
      power: 2.0
      norm: "slaney"
      mel_scale: "htk"