model:
  name: vqvae_lvl_2
  sample_rate: 44100
  slice_length: 0.7430386 # Length of slice to get 2^15 samples
  hidden_size: 64
  latent_width: 128
  latent_depth: 8
  vocabulary_size: 8192
  bottleneck_kernel_size: 0
  channel_dim_change_list: [2, 2, 2]
  sin_locations: []
  amp: False
  input_channels: 8

  encoder_kernel_size: 5
  encoder_dim_change_kernel_size: 5
  decoder_kernel_size: 7
  decoder_dim_change_kernel_add: 12

learning:
  batch_size: 8
  learning_rate: 0.0005
  weight_decay: 0.0
  epochs: 500
  gradient_clip: 0.5
  beta_ema: 0.9999
  eval_split_factor: 0.01
  monitored_loss: Validation total loss
  dataset_path: data/music_samples/
  scheduler_type: 'none'
  dataset_name: 'lvl2_dataset'
  eval_split_factor: 0.01


loss:

  reconstruction_loss:
    weight: 1.0
    base_loss_type: 'huber_loss'
    phase_parameter: 1

  alignment_loss:
    weight: 2.5
    base_loss_type: 'l2_loss'

  commitment_loss:
    weight: 2.5
    base_loss_type: 'l2_loss'